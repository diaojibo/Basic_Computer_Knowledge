## 贝叶斯决策
**贝叶斯决策以基本概率论为基础，所以可以复习概率统计相关笔记，回忆概率统计基础**。

贝叶斯分类主要借助概率论的知识来通过比较提供的数据属于每个类型的条件概率, 将他们分别计算出来然后预测具有最大条件概率的那个类别是最后的类别。当然样本越多我们统计的不同类型的特征值分布就越准确，使用此分布进行预测则会更加准确。

### 贝叶斯准则
首先先回忆一下条件概率：

条件概率：

P(A|B) = P(AB) / P(B)

其中P(A|B)表示的B发生的情况下A发生的概率，这就是条件概率(结合概率统计相关笔记,可知即是面积B中，A占的比例)。


朴素贝叶斯分类器中最核心的便是贝叶斯准则，他用如下的公式表示:

![](image/bayes0.jpg)

根据概率统计的基础，我们很容易得知，贝叶斯定理无非就是在已知结果的情况下，求后验概率。根据条件概率公式可以轻易推得贝叶斯定理。

我们的贝叶斯模型便是通过贝叶斯准则去计算某个样本在不同类别条件下的条件概率并取具有最大条件概率的那个类型作为分类的预测结果。

### 连续随机变量的贝叶斯定理
贝叶斯定理不仅仅适用于离散随机变量，还适用于连续随机变量(连续随机变量详见概率统计笔记)。

假定我们有连续随机变量X,大写P(X=x)表示概率，小写的p代表随机变量X的随机密度函数。

假如我们我们有两个类别w1,w2,x是随机变量的取值,则我们可以画出w1,和w2下，X的密度函数

![](image/bayes1.jpg)

可以这么理解，假如我们钓鱼，钓到的鱼可能有两种,w1鱼和w2鱼,x是鱼的重量,上图就是概率密度函数。那么我们就可以用已知的一些数据去知道不同重量下，w1还是w2的概率。

以下就是贝叶斯定理的推广：

![](image/bayes2.jpg)

在已经掉出一条鱼，并且得知重量的情况下，倒推鱼属于哪一类。也就是在求后验概率。要用到概率密度函数p来求。其中p(x)为每种w类下，p(x)的值之和。

![](image/bayes3.jpg)

如此我们便可根据后验概率的大小，判断类别了。

![](image/bayes4.jpg)

### 最小误差二进制分类器
分类的时候我们要考虑错误率，而比较常用的错误率函数loss function，就是01 loss function。

**最小误差分类器中，误判是等代价的，所有用0-1损失函数**

**假定仅需要分两个类，我们根据公式判断出来的类为α1/α2,变量实际属于ω1/ω2**,则有：

![](image/bayes5.jpg)

则我们有Risk风险函数，公式为

![](image/bayes6.jpg)

Risk函数的含义就是判断w类时，判断错误的风险。我们应该选风险小的。然后我们就可以根据Risk函数来判定x到底属于哪个类了

![](image/bayes7.jpg)

所以可以看到，我们是选择Risk函数小的来作为判定类别。

由于我们使用的是01 loss function，那么本质上就是：

![](image/bayes8.jpg)

这么一看来，01 loss function本质上并没有对纯粹的贝叶斯决策进行到优化。

#### 最小化总风险(penalizing权重加大)
01 loss function并没有进行到优化，然而有些情况，我们要对判断错误时，惩罚的权重加大。

比如，判断癌症时，我们把癌症病人误判为正常的危害性远远比把正常人误判为癌症的危害性大。所以我们要对把癌症病人误判这个惩罚Penalizing加大。

![](image/bayes9.jpg)

如上图，权重分配，则有：

![](image/bayes10.jpg)

说明有时候，我们甚至要允许杀错也不要放过。

![](image/bayes11.jpg)

#### 多类别情况的最小错误率分类
![](image/bayes12.jpg)

本质上还是一样的，只不过要多给出几个权重，并且要多给出几个Risk公式而已。

### 贝叶斯决策的判别函数

#### Binary分类器
对于简单的二类分类器，分类器的 **边界(Boundary)** 为：

![](image/bayes13.jpg)

我们对P(ω1|x)取log对数，可以得到：

![](image/bayes14.jpg)

我们令g(x)为决策面式子左边减去右边，有

![](image/bayes15.jpg)

则我们用这个分类器判别函数判定类别的时候就可以有：

![](image/bayes16.jpg)

上述g(x)就是贝叶斯二类分类器的判别函数，决策面Decision Boundary为

![](image/bayes17.jpg)

#### 具有相同方差的单变量二类分类器
假定随机变量的方差为μ,方差为σ，则给出概率密度函数为：

![](image/bayes18.jpg)

得到概率密度函数以后，我们依然可以代入判别函数g(x)的式子进行化简

![](image/bayes15.jpg)

![](image/bayes19.jpg)

![](image/bayes20.jpg)

#### 具有相同协方差的多变量二类分类器

![](image/bayes21.jpg)

![](image/bayes0.png)

依旧代入公式可得g(x),

![](image/bayes22.jpg)

#### 具有任意协方差的二类分类器
同理，两边取对数后代入概率密度函数化简。

概率密度函数为

![](image/bayes23.jpg)

注意，此时跟二类分类器比，协方差矩阵是不同的了。二类分类器的协方差矩阵，都是一个方差相同的对角矩阵。

化简可得

![](image/bayes24.jpg)

有具体数据，代入上面公式即可。
