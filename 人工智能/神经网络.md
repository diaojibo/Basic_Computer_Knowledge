## 神经网络
![](image/ann0.png)

人的神经网络如上图，外部刺激通过神经末梢，转化为电信号，转导到神经细胞（又叫神经元）。无数神经元构成神经中枢。神经中枢结合各种信号，做出判断，输出电信号。人体也由无数个这样的神经细胞构成。

既然思考的基础是神经元，如果能够"人造神经元"（artificial neuron），就能组成人工神经网络，模拟思考。上个世纪六十年代，提出了最早的"人造神经元"模型，叫做"**感知器**"（perceptron），直到今天还在用。

![](image/ann1.png)

上图的圆圈就代表一个感知器。它接受多个输入（x1，x2，x3...），产生一个输出（output），好比神经末梢感受各种外部环境的变化，最后产生电信号。

zwlj:把神经元，也就是中间的圆圈想象成一个函数，给出一定的输入，经过这个函数的转换，给出output值。

### 决策模型
单个的感知器构成了一个简单的决策模型，已经可以拿来用了。真实世界中，实际的决策模型则要复杂得多，是由多个感知器组成的多层网络。

![](image/ann0.jpg)

这张图里，信号都是单向的，即下层感知器的输出总是上层感知器的输入。现实中，有可能发生循环传递，即 A 传给 B，B 传给 C，C 又传给 A，这称为"**递归神经网络**"（recurrent neural network）

![](image/ann2.png)

#### hidden layer

![](image/ann4.jpg)

输入与输出层中间有很多隐藏层。


#### synapse突触

![](image/ann5.jpg)

神经网络ANN中，神经元之间的连线，就是synapse突触。每个突触都有它的权重w。

突触的任务很简单，那就是传播value，经过的value乘上权值以后传递给下一个神经元。

#### neuron神经元

![](image/ann6.jpg)

神经元就干两件事，一个是讲传递来的输出累加，一个就是使用**激活函数activation function**，对传递来的变量进行运算。

### 矢量化
那么整个ANN人工神经网络，就可以矢量化表示

![](image/ann1.jpg)

![](image/ann7.jpg)


如上图，假如传递进去一个向量(也可以理解为两个变量x1,x2，或者说特征),3和5,那么经过突触，传递到不同的式子就有相应的值。

![](image/ann8.jpg)

把传递进入的变量变成矩阵表示的话，就是上面的图。


### 神经网络运作

一个神经网络的搭建，需要满足三个条件。

 - 输入和输出
 - 权重（w）和阈值（b）
 - 多层感知器的结构


 最困难的部分就是确定权重（w）和阈值（b）。目前为止，这两个值都是主观给出的，但现实中很难估计它们的值，必需有一种方法，可以找出答案。

 这种方法就是试错法。**其他参数都不变，w（或b）的微小变动，记作Δw（或Δb）**，然后观察输出有什么变化。不断重复这个过程，直至得到**对应最精确输出的那组w和b**，就是我们要的值。这个过程称为模型的训练。

 因此，神经网络的运作过程如下。

1. 确定输入和输出
2. 找到一种或多种算法，可以从输入得到输出
3. 找到一组已知答案的数据集，用来训练模型，估算w和b
4. 一旦新的数据产生，输入模型，就可以得到结果，同时对w和b进行校正


可以看到，整个过程需要海量计算。所以，神经网络直到最近这几年才有实用价值，而且一般的 CPU 还不行，要使用专门为机器学习定制的 GPU 来计算。

#### 显卡与CPU
为什么偏向于使用GPU来计算呢？因为一般来说，显卡都有大量和core，现在的CPU一般都是4核或者8核。而显卡可能有几千个核，如果计算非常密集，显卡并发性显然非常好。CPU的架构虽然更复杂，刚强大，但是这样的密集计算，显然交给并行度更大的显卡更好。

#### sigmoid函数
Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。以前经常会把它用作激活函数activation function。

![](image/ann9.jpg)

在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的阈值函数，将**变量映射到0,1之间**。

#### Nomalization
由于激活函数Sigmoid经常把输出映射到0-1，所以我们最后输出也经常是0-1，为了和训练集对应起来，我们要对训练集做一下normalization。

![](image/ann10.jpg)

可以直接除以逻辑上的最大值，比如test score的100，也可以在训练集中，除以已有max的值。
