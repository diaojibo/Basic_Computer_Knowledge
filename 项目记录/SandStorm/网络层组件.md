# 网络层组件
为了分布式通信系统的实现，编写了一套网络层组件，在sandstorm的network目录下。


## 线程安全的消息队列
ConcurrentQueue实现了一个线程安全的消息队列，利用了c++中的mutex和lock。

里面有push pop方法，每次调用时都会用lock_guard对消息队列上锁，注意pop方法中，使用std::move来触发移动构造函数(可见c++ move相关笔记)

除此之外还有Size方法和Empty方法，也是线程安全的方法。

此类在util目录下

## 线程池
线程池来管理线程，从而提高性能。

线程池的实现也并不复杂，头文件里定义了一个模板类，接受一个泛型Type。线程池类里封装了几个私有变量

 - _shutdown布尔值,指示线程池开关
 - _threads指示线程池容量大小(int32)
 - _handler指示线程池封装的执行函数
 - _workers是一个vector容器用来封装线程
 - _tasks封装了一个消息队列

此外，类中有一个Submit方法，用来提交一个Type的实例，handler里封装的function的函数恰好类型就是(Type->void)，所以每当有一个实例提交上来，线程池就会分配一个线程，然后传递参数执行handler方法。

**由于C++中模板的限制,无法将声明和实现分离，因此为了分离声明和实现，把线程池的实现代码写在了一个后缀为tcc的文件当中，意为模板实现C++代码，然后头文件末尾包含此tcc文件**

线程池tcc中的实现也很简洁，现在来考虑线程池的实现思想，我们需要一个在随时submit一个task进入池中，池子中如果没有空闲线程则不工作，如果有空闲线程则执行任务。那么我们投递的task进入哪里呢？显然就是**消息队列**。

那么具体线程池的实现就很明朗了，初始化线程vector，并且创建函数对象并且传递进去(使用lambda)。

``` c++
for (int32_t i = 0; i < _threads; ++i)
    _workers.emplace_back(
            [this] {
                while (!_shutdown) {
                    Type record;
                    _tasks.Pop(record, true);
                    _handler(record);
                }
            }
    );
```

如上代码，注意使用了vector的emplace_back方法而不是push_back，区别在于emplace_back方法是对于变量的原地构成(直接把临时变量拿来用),而push_back则会是先调用构造函数，再(可能)调用移动构造函数，再传值，再销毁临时变量，有消耗。

上面代码指示了，一个lambda函数，任务就是只要线程池没有关闭，就不断从线程安全的消息队列里取消息。执行任务。

此类也在util目录下

## 字节序封装
见c++中的大小端字节序笔记，我们知道不同cpu处理自己的字节序不同，我们需要让这些字节在网络中传输，TCP规定要用大端，所以我们必须做一层封装，把当前字节序转换成大端。当然，也要封装方法，将tcp中的大端字节正确转换成当前cpu使用的字节。

头文件Exendian.h在utils目录下

## 序列化实现
手动实现一个字节流类，可参见序列化实现笔记，完全一模一样。

唯一的不同点在于，ByteReader里添加了转换网络中的大端字节数据的方法。可以让host使用的字节流与TCP字节流相互转化。



## 抽象TP传输层实现
我们利用epoll来实现对传输层的封装。

主要的类位于network目录下的Net.h头文件当中，内部定义了几个类

### Socket类
通用的套接字层，其实仅仅也就是对套接字文件描述符的一个封装，内部仅仅封装一个整数为socket的fd。析构函数中定义了close方法。


### IStream接口
通用数据流层，代表所有**可读写的数据流类接口**，可以理解为对输入输出字节流(ByteArray)数据操作的再一层封装，也就是说直接用它来操作IO数据,内部会有一个数据接收器datasink。

里面的核心方法有

 - Recieve,指定一个缓冲区，数据流将**读取到的数据**填充到缓冲区。
 - Send,发送数据，将用户传递的字节数组发送出去。

### IConnectable
一个接口interface，表示某类可以**主动** 连接到其他服务器。**client** 都会实现这个接口,server不需要实现这个接口。

只有一个函数Connect,接受两个参数，远程主机名，和端口，用于连接到远端服务器。

### BasicStream
基本的数据流类，继承了IStream接口，也继承了Socket，也就是融合了Socket和IStream，即可通过Socket文件描述符，在此基础上来读写数据流。此外也封装了DataSink数据收集器。

### BasicServer
服务器类，继承了socket接口，封装了服务器的常用方法，如bind，accept，listen。

### DataSink\&\&PackageDataSink
DataSink是数据接受层，传输层接受到数据时会通过DataSink对象传输到外部

PacakgeDataSink就是DataSink的子类，它里面封装了一个ByteArray，可以通过Write方法，向io流(IStream)写数据(ByteArray).

## 基于epoll的TP传输层
Epoll封装后的传输层主要分为以下几个组件：EpollLoop，EpollServer，EpollClient，EpollStream。接下来这里将详细记录每个组件的作用


### EpollLoop
我们基于epoll的笔记都知道，我们使用epoll时，需要创建一个epoll的文件描述符统一管理fd(事件),用epoll_ctl去注册事件，然后用一个无限Loop去调用epoll_wait.一旦有事件(IO就绪)，epoll_wait就会返回让用户处理。

我们现在就将这个Loop封装成一个类，经过这样的封装，我们可以使底层的网络调用更加智能化。

EpollLoop是传输层的核心组件，它支撑起整个Epoll循环，使得轮询IO自动化。

EpollLoop类继承(实现)了Loop接口，这个Loop接口中也只有一个_Run方法，我们通过这个Run方法来启动整个循环，只要Run被调用，Epoll将会分离出一个线程来进行循环，这个在之后也会提到。

#### EpollLoop为单例
EpollLoop在进程中有一个就够了，所以做成单例模式，用Get方法获取，Get方法中，有一个static的实例，构造方法要设置成private，防止外部意外调用。

#### EpollLoop构造和初始化
EpollLoop里面封装了一个fd，根据epoll笔记，我们知道基于Epoll进行IO管理时，Epoll会先创建一个fd来管理其他fd(事件)。

所以显然在EpollLoop的构造方法中，我们需要进行管理fd文件的创建(**私有成员变量_events为管理fd**)

我们在构造方法里会调用Initiate方法，这个方法无非就是调用epoll_create,返回一个fd管理文件。将其封装进私有变量中持有。(算是完成了epoll第一步)

除此之外，EpollLoop构造方法里还进行了SIGPIPE信号的屏蔽处理(可见相关笔记)。防止连接到一个已经关闭的对端从而导致进程退出。

#### EpollLoop析构
析构就是将EpollLoop内部封装的标志(bool)变量shutdown置为true，这样循环线程就会停止工作。

#### Server与流管理
**EpollLoop封装了两个Map，一个map用来管理server，一个map用来管理流(stream)**.两个map都是根据文件描述符int来检索具体的server对象或者流对象。

EpollLoop有个**AddServer成员函数**，可以添加创建好的server对象进入map中。

同理也有**AddStream成员函数**，用来添加Stream进map中。我们知道一个stream就是IO和socket的一个封装，所以通过管理这些stream，我们将能自动化实现事件监听。

#### EpollLoop事件管理
EpollLoop的作用是帮助我们自动监听IO事件，所以当然就需要有方法来让用户们去修改添加事件。也就是说**本质上就是调用epoll_ctl方法**(epoll操作第二步)。

所以**AddEpollEvent成员方法**就是对epoll_ctl的封装，这个方法接受两个参数，第一个参数events是代表事件类型，比如说这个事件的可读事件(EPOLLIN)，还是可写事件(EPOLLOUT)，亦或是设置水平触发。最后把这些事件注册进EpollLoop的管理fd中。

同理**ModifyEpollEvents**方法就是对监听的注册事件进行修改，也是对epoll_ctl的封装。

#### EpollLoop启动循环
我们首先会调用Run方法来启动整个EpollLoop，但是循环并不是在Run方法中，Run方法的作用是新建一个线程Thread并执行EpollThread方法，这样循环就会在新线程中进行而不会阻塞住整个服务器进程。

EpollThread就是真正进行整个EpollLoop的地方，只要shutdown标志不是true，就进行永久的while循环，循环内当然就是进行监听epoll时间的第三步epoll_wait。根据IO复用模型，调用wait之后就是阻塞线程，然后操作系统轮询IO，一旦有IO事件发生，就返回事件数组。

然后EpollLoop就会调用HandleEvents方法，去逐个处理事件。

#### Epoll事件处理
在HandleEvents方法中，遍历事件数组一一处理，先察看事件struct，分别得到IO事件的类型(读还是写),和相应的fd。

如果发现fd是已经在Loop里注册的server，那说明这个事件是有client来连接server了，这时应该调用acept方法让server去接受这个client。

如果这个fd不是server，且事件是读事件，说明是个IO流(connection),那我们就调用_Read方法去读这个IO流传输来的数据。

#### Accept事件
调用server自身的Accept方法会得到一个Connection，Connection本质就是一个IO流(IO操作+Socket fd封装),将这个Connection添加进Loop的Connection Map中管理即可。

#### Read读取数据
当事件是读事件时，我们调用_Read方法去读取这个Connection(IO流)的数据。我们调用流的Receive方法获取buffer数据，然后再次设置event类型(可读还是可写)。**使得下次处理流对象时可以正确还原状态**

最后我们调用_Enqueue方法，去处理这些读写到的数据。

#### _Enqueue方法
_Enqueue方法将Connection读取来的数据推去对应的处理函数处理，这个处理函数是封装在stream中的。就是stream里封装的变量DataSink。

所以也可以知道Stream这个抽象概念不仅封装了IO操作，还封装了IO收集到数据之后的行为(如何处理数据)。


### EpollStream
在之前的基本组件里，我们定义了IStream,那么Stream本质上就是IO操作封装了Socket文件描述符，我们通过Stream进行操作，那就是调用自身的读写方法，读写Socket文件。

而EpollStream就是基于Epoll实现的Stream，

EpollStream内部封装了一个成员变量_events,来说明当前stream是什么Epoll类型的。我们知道epoll操作中，我们需要使用epoll_ctl来指定事件类型，所以这个变量用来记录event类型。

除此之外，有receive成员函数，封装了read操作。在EpollLoop监听到读事件到来以后，会调用Stream的recieve方法来读取数据，所以必然是封装了recv或read操作。

同理还有send成员函数用来发送字节数组ByteArray.会调用EpollLoop的ModifyEvent来修改监听事件，注册读事件。然后循环write这个套接字。

### EpollServer
EpollServer，服务器类，本质上也是对一个Socket的封装，继承了BasicServer类,Accept之后会返回一个EpollConnection，这个EpollConnection本质上就是一个EpollStream。

EpollServer里面有典型的几个服务器方法，Bind,Listen，Accept。

Bind无需我们调用，我们只需要调用Listen方法，它将会内部调用bind，把服务器Ip和port绑定起来，并且监听。socket也被设置成非阻塞模式的。

监听成功之后，会把自己设置到EpollLoop中进行管理。

Accept方法本质上也是对epoll_ctl的一个封装。Accept成功后会返回一个Connection。

### EPollClient
EpollClient，客户端类，继承自EpollConnection，所以本质上就是一个IO流而已。只不过在IO流的基础上多一个Connect成员方法(实现了IConnectable接口)

EpollClient的Connect方法需要传递一个DataSink，数据处理器，设置在流中，用以接受到数据以后可以将数据发送打别的地方进行处理(比如threadpool)。

connect之后，还会在EpollLoop中注册监听事件，监听server发给自己的消息。

## 事件队列eventQueue

### 事件event
事件对象封装了三个私有变量，封装了一个IStream，一个ByteArray字节数组，一个int变量type。

本质上也就是封装了一个字节数组和一个IO流(IStream)。

### eventQueue
事件队列，一个线程安全的事件队列，本质上是一个生产者消费者队列，内部有线程安全的postEvent和getEvent方法来生产和消耗事件。

内部是一个vector的封装，vector中装的是event的智能指针。
