## 缓存技术基础
对于构建高性能、高可用的大型互联网系统，缓存是不可或缺的组成部分

传统的后端业务场景中，访问量以及对响应时间的要求均不高，通常只使用DB即可满足要求。这种架构简单，便于快速部署，很多网站发展初期均考虑使用这种架构。但是随着访问量的上升，以及对响应时间的要求提升，单DB无法再满足要求。这时候通常会考虑DB拆分(sharding)、读写分离、甚至硬件升级(SSD)等以满足新的业务需求。

但上述也有缺点：

 - 性能提升有限，很难达到数量级上的提升，尤其在互联网业务场景下，随着网站的发展，访问量经常会面临十倍、百倍的上涨。
 - 成本高昂，为了承载N倍的访问量，通常需要N倍的机器，这个代价难以接受。

同时我们也注意到，内容访问复合二八原则：

![](image/cache0.jpg)

大部分的业务场景下，80%的访问量都集中在20%的热数据上(适用二八原则)。因此，通过引入缓存组件，将高频访问的数据，放入缓存中，可以大大提高系统整体的承载能力，原有单层DB的数据存储结构，也变为Cache+DB的结构

下面介绍一下常用的缓存组件：

### Memcached
Memcached是开源的，高性能的，可分布式部署，用于网站提速，减轻数据库负载的缓存组件

有如下特点：

 - 高性能Key-Value存储
 - 协议简单：简单文本协议、二进制协议
 - 支持数据过期
 - LRU剔除算法
 - 多线程
 - slab内存管理
 - 客户端实现分布式       

#### 内存管理

Memcached使用Slab Allocator的机制来实现分配、管理内存，按照预先规定的大小，将分配的内存分割成特定长度的块，以此来解决内存碎片问题，如图：

![](image/cache1.jpg)

**​slab是特定大小的chunk的组**，并根据增长因子(factor)，划分成不同slab class。如上图就分为4个class，每个class的组，chunk大小也都不一样。

每次分配一个page(默认1MB)给某个slab(可以理解为一个slab会被分配一个page大小的内存)，并根据slab的大小，切分成多个chunk，数据存储在chunk中。**Memcached根据收到的数据的大小，选择最适合数据大小的slab**

![](image/cache2.jpg)

 Memcached的Slab Allocator内存分配方式会存在内存浪费的问题，主要有以下几种情况：

  - chunk浪费: 缓存数据没有填充满chunk
  - page浪费: 一个page的容量不能被slab的大小整除。
  - slab浪费: 某个slab的内存没有完全被利用，只存储了少量数据，却占用一个page。

#### 剔除算法
Memcached采用**LRU淘汰算法--最久未使用算法**，在容量满的时候进行数据剔除。不过该淘汰算法 **只在Slab内部进行**，也就是说，某个Slab容量已满时，只会在该Slab内部进行数据剔除，而不会影响其它Slab。这种局部剔除的策略也带来了一个问题：**Slab钙化**。

#### Slab钙化
某个Memcached实例的Slab状态如下：

![](image/cache3.jpg)

上图意味，有两个slab，第一个slab chunk单位是120m，第二个slab chunk单位是152m。且第一个slab被分配了6000个page也就是6g，slab2则是3.5g。

​如果此时，业务数据大小出现变更，比如超过152字节。就会出现以下问题

![](image/cache4.jpg)

 新的数据(需要使用chunk size为192)，只能最多使用500M，而原有slab class(120和152)没释放，尽管数据都已过期，因为淘汰策略是淘汰相同slab class的数据，所以一直利用不上120和152的内存，这种情况会导致缓存命中率急剧下降。


如果发生这种情况，有以下几种解决方案：

 - 重启Memcached实例，简单粗暴，需要避免单点问题，避免出现雪崩

 - 随机过期，过期淘汰策略也支持淘汰其他slab class的数据，twitter和facebook等均作了类似支持

 - 通过slab_reassign、slab_authmove，官方1.4.11版开始支持此功能

### redis
Redis是开源的，高性能的，支持分布式，支持多数据结构的缓存组件(详细笔记将记到数据库目录下)。特点如下


 - 高性能Key-Value存储
 - 丰富的数据结构：string、list、hash、set、zset、hypeloglog
 - 支持数据过期：主动过期+惰性过期
 - 支持多种LRU策略：volatile-lru、volatile-ttl 等
 - 内存管理：tcmaloc、jemalloc
 - 内存存储+磁盘持久化: rdb、aof
 - 支持主从复制
 - 单线程


### 分布式缓存基础
构建大型互联网系统会面临很多的挑战，主要有：

 - 百万级QPS的资源调用 (高并发)
 - 99.99%的可用性 (高可用)
 - 毫秒级的核心请求响应时间 (高性能)

 设计这样的互联网系统，**不可避免的要考虑使用分布式缓存，并从可用性、并发性、性能多个方面进行综合考量**。

下面介绍一下分布式缓存的实现方式：

#### 数据分片
数据分片就是把数据均匀分散到多个实例中。

数据分片(也可以理解为根据key值找机器)可以采用以下几种规则：区间分片、hash分片、 slot分片。对于hash分片，主要的哈希算法有静态哈希和一致性哈希，静态哈希和一致性哈希对比如下：

 - 静态哈希(取模求余) 优点：算法简单，缺点：加减节点时震荡厉害, 命中率下降厉害
 - 一致性哈希，优点：加减节点时震荡较小, 保持较高命中率。 缺点：自动rehash场景下会数据不一致的问题(同一份数据的请求在不同节点漂移)


#### 可用性
线上使用过程中，如果出现某些缓存实例不可用，大量请求穿透会给DB带来巨大的压力，极端情况会导致雪崩场景，这需要有更好的方式保证缓存的高可用。于是我们采用用主从(Master/Slave)的架构，如图。也就是在原有单层缓存的结构下，增加一层Slave，来保证即使某个Master节点宕机，整个缓存层依然是可用的，不会出现大量请求穿透DB的情况。

![](image/cache5.jpg)


### redis、memcache两者对比

 - 性能：由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据时，Memcached性能要高于Redis(单线程会被阻塞)，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。

 - 数据类型:Redis支持的数据类型要丰富得多,Redis不仅仅支持简单的k/v类型的数据，同时还提供String，List,Set,Hash,Sorted Set,pub/sub,Transactions数据结构的存储。其中Set是HashMap实现的，value永远为null而已.memcache支持简单数据类型，需要客户端自己处理复杂对象

 - 持久性,redis支持数据落地持久化存储,可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
memcache不支持数据持久存储

 - redis支持master-slave复制模式,memcache可以使用 **一致性hash做分布式**。Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。Redis是可以使用Redis cluster，具体见数据库部分的后续笔记。


Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别

#### 线程模型
Redis使用单线程实现，Memcache等使用多线程实现，因此我们不推荐在Redis中存储太大的内容，否则会阻塞其它请求。

因为缓存操作都是内存操作，只有很少的计算操作，所以在单线程下性能很好。Redis实现的单线程的非阻塞网络I/O模型，适合快速地操作逻辑，有复杂的长逻辑时会影响性能。对于长逻辑应该配置多个实例来提高多核CPU的利用率，也就是说，可以使用单机器多端口来配置多个实例，官方的推荐是一台机器使用8个实例。

#### 持久机制
Redis提供了两种持久机制，包括RDB和AOF，前者是定时的持久机制，但在出现宕机时可能会出现数据丢失，后者是基于操作日志的持久机制。

Memcahe并不提供持久机制，因为Memache的设计理念就是设计一个单纯的缓存，缓存的数据都是临时的，不应该是持久的，也不应该是一个大数据的数据库，缓存未命中时回源查询数据库是天经地义的，但可以通过第三方库MemcacheDB来支持它的持久性。

#### 高可用
Redis支持主从节点复制配置，从节点可使用RDB和缓存的AOF命令进行同步和恢复。Redis还支持Sentinel和Cluster（从3.0版本开始）等高可用集群方案。

Memecache不支持高可用模型，可使用第三方Megagent代理，当一个实例宕机时，可以连接另外一个实例来实现。

#### 事务
Redis提供了一些在一定程度上支持线程安全和事务的命令，例如：multi/exec、watch、inc等。由于Redis服务器是单线程的，任何单一请求的服务器操作命令都是原子的，但跨客户端的操作并不保证原子性，所以对于同一个连接的多个操作序列也不保证事务。

Memcached的单个命令也是线程安全的，单个连接的多个命令序列不是线程安全的，它也提供了inc等线程安全的自加命令，并提供了gets/cas保证线程安全。

#### 数据淘汰策略
Redis提供了丰富的淘汰策略，包括maxmemory、maxmemory-policy、volatile-lru、allkeys-lru、volatile-random、allkeys-random、volatile-ttl、noeviction(return error)等。

Memecache在容量达到指定值后，就基于LRU（Least Recently Used）算法自动删除不使用的缓存。在某些情况下LRU机制反倒会带来麻烦，会将不期待的数据从内存中清除，在这种情况下启动Memcache时，可以通过“M”参数禁止LRU算法。

#### 内存分配
Redis为了屏蔽不同平台之间的差异及统计内存占用量等，对内存分配函数进行了一层封装，在程序中统一使用zmalloc、zfree系列函数，这些函数位于zmalloc.h/zmalloc.c文件中。封装就是为了屏蔽底层平台的差异，同时方便自己实现相关的统计函数。

Memcache采用slab table的方式分配内存，首先把可得的内存按照不同的大小来分类，在使用时根据需求找到最接近于需求大小的块分配，来减少内存碎片，但是这需要进行合理配置才能达到效果。

#### zwlj
所以总结一下，Redis的单线程，难以利用到多核，所以大数据的时候有性能限制。但是类型丰富，支持集群操作和持久化操作。

memcached优点是多线程，可以利用多核，吞吐量大。但是数据类型少，无法进行持久化，分布式要客户端自己实现一致性哈希。内存管理方面，如果value的大小分布差异很大，可能会造成内存利用率降低(比如我存个1k数据，突然又存个500k。肯能会生成一些浪费的slab)


### 参考
[分布式缓存架构基础](https://juejin.im/entry/57e39e320e3dd90058021bff)
