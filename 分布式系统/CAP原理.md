## CAP原理
CAP 原理最早由 Eric Brewer 在 2000 年，ACM 组织的一个研讨会上提出猜想，后来 Lynch 等人进行了证明。

该原理被认为是分布式系统领域的重要原理。

**分布式计算系统不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition），设计中往往需要弱化对某个特性的保证。**


对于分布式数据系统，分区容忍性是基本要求，否则就失去了价值.对于大多数web应用，其实并不需要强一致性，因此牺牲一致性而换取高可用性，是目前多数分布式数据库产品的方向。

### 一致性
分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

所以强一致性指的就是，任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果。这种**事务特性**

对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。

### 可用性
集群出现故障节点后，是否还能响应客户端的读写请求。（对数据更新具备高可用性）

### 分区容忍性
实际中通信产生延时。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C点和A点之间做出选择。

网络可能发生分区，即节点之间的通信不可保障。

### CAP证明

![](image/cap0.png)

如上图，是一个正常理想情况下的分布式系统。v是数据库，N1和N2是分布式系统下两个不同的节点。A和B可以理解为分布式系统下的两个客户端进程。

正常流程下，图1 A更新数据到v0，然后图2 N1更新数据M到N2，从而B能正确获得数据库的数据。

但是事实总不是理想的，假定极端地，网络很差的情况下：N1和N2之间的网络断开了，**我们要支持这种网络异常，相当于要满足分区容错性(这是大前提，先满足了分区容错性)**

![](image/cap1.png)

假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？

有二种选择：
1. **牺牲数据一致性**，响应旧的数据V0给用户
2. **牺牲可用性**，阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。

这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。


好在大部分时候网络被认为是可靠的，因此系统可以提供一致可靠的服务；当网络不可靠时，系统要么**牺牲掉一致性（大部分时候都是如此）**，要么牺牲掉可用性。

### 应对
既然 CAP 不可同时满足，则设计系统时候必然要弱化对某个特性的支持。

#### 弱化一致性
对结果一致性不敏感的应用，可以**允许在新版本上线后过一段时间才更新成功，期间不保证一致性**。

例如网站静态页面内容、实时性较弱的查询类数据库等，CouchDB、Cassandra 等为此设计。

#### 弱化可用性
对结果一致性很敏感的应用，例如银行取款机，当系统故障时候会拒绝服务。MongoDB、Redis 等为此设计。

Paxos、Raft 等算法，主要处理这种情况。

#### 弱化分区容忍性
现实中，网络分区出现概率减小，但较难避免。某些关系型数据库、ZooKeeper 即为此设计。

实践中，网络通过双通道等机制增强可靠性，达到高稳定的网络通信。
